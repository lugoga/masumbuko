<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Masumbuko Semba on Masumbuko Semba&#39;s Blog</title>
    <link>/tags/masumbuko-semba/</link>
    <description>Recent content in Masumbuko Semba on Masumbuko Semba&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/masumbuko-semba/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Integrate R and Python in Rstudio to Power Your Analytical Capability</title>
      <link>/07/10/2020/integrate-r-and-python-in-rstudio-to-power-your-analytical-capability/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/07/10/2020/integrate-r-and-python-in-rstudio-to-power-your-analytical-capability/</guid>
      <description>If you work with data science, R and Python must be the two programming languages that you use the most. Both R and Python are quite robust languages and either one of them is actually sufficient to carry out the data analysis task. However, instead of considering them as tools that supplement each other, more often you will find people dealing with data claim one language to be better than the other.</description>
    </item>
    
    <item>
      <title>Mapping with cartopy in python</title>
      <link>/07/04/2020/mapping-with-cartopy-in-python/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/07/04/2020/mapping-with-cartopy-in-python/</guid>
      <description>Today we will learn about Cartopy, one of the most common packages for making maps within python. Another popular and powerful library is Basemap; however, Basemap is going away and being replaced with Cartopy in the near future, For this reason, investing your time in learning mapping in python with Cartopy module is recommended.
We thank Research in Computing Earth Sciences because most of material in this post are gleaned from their website.</description>
    </item>
    
    <item>
      <title>Kernel smoothing of Spatial Data</title>
      <link>/06/30/2020/kernel-smoothin-of-spatial-data/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/30/2020/kernel-smoothin-of-spatial-data/</guid>
      <description>Kernel density estimation is a popular tool for visualizing the distribution of data. In this post, we are going to look on how to create smoothed map of random points. We will use a shapefile dataset that contains potential fishing zones derived from sea surface temperature recorded between January and June 2020 in Pemba channel. You can simply download the file from this link.
Once you have downloaded the file, unzip and browse in the uncompressed file you find the shapefile pfz.</description>
    </item>
    
    <item>
      <title>Processing NECTA Results in R</title>
      <link>/06/14/2020/processing-necta-results-in-r/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/14/2020/processing-necta-results-in-r/</guid>
      <description>The the National Examinations Council of Tanzania publishes Primary and Secondary Education Examination Results. But the National Library Services archieve this results. While a fantastic resource for history primary and secondary school results, these records are painful to analyze using software because of the grades results is organized is untidy and in messy.
You need to work on this column of the result to have a clean and right format dataset for exploration and modelling.</description>
    </item>
    
    <item>
      <title>Interactive Plots and  Maps in R</title>
      <link>/06/13/2020/plots-in-interactive-maps-with-r/</link>
      <pubDate>Sat, 13 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/13/2020/plots-in-interactive-maps-with-r/</guid>
      <description>IntroductionOften times when w are working with data, there always a geospatial component to the data—the locations. Most of us have used static maps to reveal information that other plots can not. And interactive maps can enliven geographic information to new insights. The most important type of interactivity, is the display of geographic data on interactive or ‘slippy’ web maps. Interactivity can take many forms, the most common and useful of which is the ability to pan around and zoom into any part of a geographic dataset overlaid on a ‘web map’ to show context.</description>
    </item>
    
    <item>
      <title>A simple Principal Component Analysis (PCA) in R </title>
      <link>/05/13/2020/simple-pca-in-r/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/13/2020/simple-pca-in-r/</guid>
      <description>Principal Component Analysis (PCA)Principal Component Analysis (PCA) is widely used to explore data. This technique allows you visualize and understand how variables in the dataset varies. Therefore, PCA is particularly helpful where the dataset contain many variables.This is a method of unsupervised learning that allows you to better understand the variability in the data set and how different variables are related.
The Components in PCA are the underlying structure in the data.</description>
    </item>
    
    <item>
      <title>Linear and Bayesian Regression Models with tidymodels package</title>
      <link>/05/11/2020/regression-with-tidymodels/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/11/2020/regression-with-tidymodels/</guid>
      <description>As a data scientist, you need to distinguish between regression predictive models and classification predictive models. Clear understanding of these models helps to choose the best one for a specific use case. In a nutshell, regression predictive models andclassification predictive models` fall under supervised machine learning. The main difference between them is that the output variable—in regression is numerical (or continuous) while that for classification is categorical (or discrete).</description>
    </item>
    
    <item>
      <title>Heatmaps in R with ggplot2 and metR packages </title>
      <link>/05/10/2020/heatmaps-in-r-with-ggplot2-and-metr-packages/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/10/2020/heatmaps-in-r-with-ggplot2-and-metr-packages/</guid>
      <description>Heatmaps are powerful data visualization tools broadly widely used with meteorologic and oceanographic data. Heatmaps are excellent at tracking signals that move, like ocean current. These diagrams can be used for many more types of atmospheric features. The concept is to represent a matrix of values as colors where usually is organized by a gradient. This post explains how to create a heatmap of ocean current in R using the geom_tile(), geom_contour_filled from ggplot2 (Wickham 2016) and geom_contour_fill from metR package (Campitelli 2019).</description>
    </item>
    
    <item>
      <title>A Unified Machine Learning in R with tidymodels</title>
      <link>/05/09/2020/a-unified-machine-learning-in-r-with-tidymodels/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/09/2020/a-unified-machine-learning-in-r-with-tidymodels/</guid>
      <description>tidymodelstidymodels is a suite of packages that make machine learning with R a breeze. R has many packages for machine learning, each with their own syntax and function arguments. tidymodels aims to provide an unified interface, which allows data scientists to focus on the problem they’re trying to solve, instead of wasting time with learning package syntax.
The tidymodels has a modular approach meaning that specific, smaller packages designed to work hand in hand.</description>
    </item>
    
    <item>
      <title>Convert incorrect filled missing values to NA in R data frame</title>
      <link>/05/06/2020/conver-improper-filled-missing-values-to-na-in-r/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/06/2020/conver-improper-filled-missing-values-to-na-in-r/</guid>
      <description>One of the most important components of a data management strategy is the proper handling of missing values. Often you will find datasets that have used either zero or NA to represent missing values in cell of a data frame or table. The question that may sober our mind is that, which of the two way of storing missing value in the data is right? You will notice that everyone who deals with data has to deal with this important distinction.</description>
    </item>
    
    <item>
      <title>Lake Victoria Bathymetry</title>
      <link>/04/24/2020/lake-victoria-bathymetry/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/04/24/2020/lake-victoria-bathymetry/</guid>
      <description>I was looking for bathymetry dataset for Lake Victoria online and I came across this link. It stores several products of the bathymetry data of the Lake Victoria. Among them products is the gridded TIFF file. This dataset was created by a team from Harvard University in 2017 (Hamilton et al. 2016). They used over 4.2 million points collected over 100-years of surveys.</description>
    </item>
    
    <item>
      <title>Model and Project the death toll of coronavirus at Wuhan Province in R</title>
      <link>/02/08/2020/model-and-project-the-death-toll-of-coronavirus-at-wuhan-province-in-r/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/02/08/2020/model-and-project-the-death-toll-of-coronavirus-at-wuhan-province-in-r/</guid>
      <description>IntroductionThe recent contagious 2019-nCoV Wuhan coronavirus outbreak in China has brought shocks and triggered panic among the general population around the world. This noval coronavirus (nCoV) is a new strain that has never been identified in humans before. The risk associated with this virus to human led the World Health Organization (WHO) of United Nations to declare 2019-nCoV as global health emergency.</description>
    </item>
    
    <item>
      <title>Text mining in R</title>
      <link>/12/02/2019/text-mining-in-r/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/12/02/2019/text-mining-in-r/</guid>
      <description>Sentiment analysis provides a way to understand the attitudes and opinions expressed in texts. In this post, we explored how to approach sentiment analysis using tidy data principles; when text data is in a tidy data structure, sentiment analysis can be implemented as an inner join. We can use sentiment analysis to understand how a narrative arc changes throughout its course or what words with emotional and opinion content are important for a particular text.</description>
    </item>
    
    <item>
      <title>plotting the Spatial distribution of Chlorophyll in Mafia Channel from MODIS</title>
      <link>/12/01/2019/plotting-the-spatial-distribution-of-chlorophyll-from-modis/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/12/01/2019/plotting-the-spatial-distribution-of-chlorophyll-from-modis/</guid>
      <description>Making graphics and maps is one of the important skills for oceanographers and marine scientists. Maps are often used by scientists to locate areas of interest—where the study being presented was conducted. Thus ability to make maps that convey the message in a simple manner form an important first impression for readers. Despite this, software tools for producing high-quality maps are non-trivial to use.
In this post I illustrate how some key lines of code for access, download and map the spatial distribution of chlorophyll-a concentration within the Rufiji-Mafia Channel using a combination of packages in the R environment.</description>
    </item>
    
    <item>
      <title>Access meteorogical observations using worldmet package</title>
      <link>/11/29/2019/access-meteorogical-observations-using-worldmet-package/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/11/29/2019/access-meteorogical-observations-using-worldmet-package/</guid>
      <description>David Carslaw (2019) developed R package worldmet, which provides an easy way to access world meteorological data from from the Integrated Surface Database of National Oceanic and Atmospheric Administration (NOAA). The Integrated Surface Database (ISD) consists of global hourly and synoptic observations compiled from numerous sources into a single common ASCII format and common data model.</description>
    </item>
    
    <item>
      <title>Wordclouds plotting with ggwordcloud package in R</title>
      <link>/11/05/2019/wordclouds-plotting-with-ggwordcloud-package-in-r/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/11/05/2019/wordclouds-plotting-with-ggwordcloud-package-in-r/</guid>
      <description>In the previous post, we saw how to make wordcloud graphic using the wordcloud package. In this post we extend the ability of R to make wordcloud graphic, but rather than using the base R function for plotting,I will show how to use ggplot2 framework.
Le Pennec and Slowikowski (2019) developed a gwordcloud package, which extend the capability of ggplot2 package (Wickham 2016) of making cloud text. With the geom_text_wordcloud() function, gwordcloud made making wordcloud plot easy with ggplot2 package.</description>
    </item>
    
    <item>
      <title>A glimpse of FAO&#39; fisheries statistics in R</title>
      <link>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</guid>
      <description>IntroductionThe OpenFisheries.org project created an open web platform aimed to advance the practice of data science in fisheries. The project has managed to consolidate global fisheries dataset that can be accessed and retrieved using modern analytics. The OpenFisheries.org flagship project is the Global Fisheries REST API forms the backbone of fisheries data science, enabling reproducible analytics in R (R Core Team, 2019), Python or any other language.</description>
    </item>
    
    <item>
      <title>Forecasting time series data with R</title>
      <link>/08/09/2019/forecasting-time-series-data-with-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/08/09/2019/forecasting-time-series-data-with-r/</guid>
      <description>introductionIn this post I illustrate how to predict the future using the historical data. Time series analysis comprises methods for predicting the future based on the historical in order to extract meaningful statistics and other characteristics of the data. In other words, time series forecasting is the use of a model to predict future values based on previously observed values.</description>
    </item>
    
    <item>
      <title>The Reasons for Creating my blog!</title>
      <link>/02/19/2019/why-i-created-a-static-blog-from-scratch/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/19/2019/why-i-created-a-static-blog-from-scratch/</guid>
      <description>According to firstpage;
…blogging was initially used as a unique platform to share a person’s thoughts, feelings, opinions or experiences—an online journal or diary with a minimal following.
Today, it has grown into a platform used by millions, everyone from individuals to businesses. The simplicity of a blog makes it easy for anyone to launch a blog and become a self-proclaimed “expert.” But how is it important in the world today, with unprecedented advent in technology and computing?</description>
    </item>
    
    <item>
      <title>Mapping with oce</title>
      <link>/02/13/2019/mapping-with-oce/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/13/2019/mapping-with-oce/</guid>
      <description>There are many different things that requires oceanographers to code and write scripts that automate routinely analytical frameworks. However, there is one common use amongst almost all every report, research project or paper will need to have—map indicating to a study area. There are many packages that are often used to make maps in R. And heaps of blog posts, books and tutorials that illustrate different ways to visualize spatial data in R.</description>
    </item>
    
    <item>
      <title>Isosurface of temperature, salinity, oxygen and fluorescence in Mafia Channel from CTD data </title>
      <link>/02/12/2019/isosurface-of-temperature-salinity-oxygen-and-fluorescence-in-mafia-channel-from-ctd-data/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/12/2019/isosurface-of-temperature-salinity-oxygen-and-fluorescence-in-mafia-channel-from-ctd-data/</guid>
      <description>Iso surfaceOften times we want to visualize the distribution of oceanographic variables across the space at specific depth. That kind of visualization refers to isosurface—layer(s) of constant values of another data variable, such as, constant depth. For this post highlights key steps to create isosurface from CTD profile data in Mafia channel. Because these channel is shallow with an average depth of 20 meters, we will calculate isosurface of f temperature, oxygen, fluorescene at the surface, 10 and 20 meters deep.</description>
    </item>
    
    <item>
      <title>Comparing classical methods for estimating the mixed layer depth along the transect off Kimbiji, Tanzania</title>
      <link>/02/09/2019/comparing-classical-methods-for-estimating-the-mixed-layer-depth-along-the-transect-off-kimbiji-tanzania/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/09/2019/comparing-classical-methods-for-estimating-the-mixed-layer-depth-along-the-transect-off-kimbiji-tanzania/</guid>
      <description>IntroductionUpper Ocean is characterized for a quasi-homogeneous layer where temperature, salinity and density almost constant with increasing depth (Costoya et al. 2014). This homogeneity layer is caused by turbulent vertical mixing that is driven by heat loss from the ocean to the atmosphere, as well as by wind stress (Stranne et al. 2018). The deepest layer affected by this turbulent mixing is called mixed layer depth (MLD), which marks the width of the upper ocean that interacts with the atmosphere (Kelley 2018).</description>
    </item>
    
    <item>
      <title>Detecting Mixed Layer Depth with Optimal Linear fitting method.</title>
      <link>/02/08/2019/different-approaches-of-detecting-mixed-layer-depth/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/08/2019/different-approaches-of-detecting-mixed-layer-depth/</guid>
      <description>IntroductionThe mixed layer is a thin layer with constant temperature and salinity from the surface down to a depth where the values differ from those at the surface (Boyer Montégut et al. 2004). Wind blowing on the ocean stirs the upper layers leading to a thin mixed layer (Stewart 2008). The resulting surface mixed layer is important for local primary production, climate and ocean circulation (Kelley 2018). Although the mixed layer is an important oceanographic parameter, there different approaches that are used and each method depends on the scientific application.</description>
    </item>
    
    <item>
      <title>Detect the Mixed Layer Depth (MLD)  along the East African Coastal Current  from   Argo floats data using criterion approach</title>
      <link>/02/01/2019/compute-the-mixed-layer-depth-mld-along-the-east-african-coastal-current-from-argo-floats-data/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/01/2019/compute-the-mixed-layer-depth-mld-along-the-east-african-coastal-current-from-argo-floats-data/</guid>
      <description>IntroductionThe ocean mixed layer is narrow band of the suface water that is homogenous—where temperature, salinity and density scarcely vary with increasing depth (Costoya et al. 2014). This homogeneity layer is caused by turbulent vertical mixing that is driven by heat loss from the ocean to the atmosphere and wind stress. The deepest layer affected by this turbulent mixing is called mixed layer depth (MLD), which marks the width of the upper ocean that interacts with the atmosphere.</description>
    </item>
    
    <item>
      <title>Determine dynamic height and geostrophic velocity along the East African Coastal Current from Argo floats</title>
      <link>/01/29/2019/determine-dynamic-height-and-geostrophic-velocity-along-the-east-african-coastal-current-from-argo-floats/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/01/29/2019/determine-dynamic-height-and-geostrophic-velocity-along-the-east-african-coastal-current-from-argo-floats/</guid>
      <description>IntroductionI have been working with argo floats data and wrote two post that illustrate how to detect the mixed layer depth with criterion and derivative approaches. In this post, I change the focus. Rather than talking about the mixed layer depth detection, I will illustrate how to calculate the dynamic height and geostrophic velocity from same dataset—Argo float. I use R programming language as an environment for the required routine to calculate the dynamic height and geostrophic current (R Core Team 2018).</description>
    </item>
    
    <item>
      <title>Programming: An Essential Skills for Scientists</title>
      <link>/11/23/2018/programming-an-essential-skills-for-scientists/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/11/23/2018/programming-an-essential-skills-for-scientists/</guid>
      <description>IntroductionIn recent years, there’s been an admirable push to get more people to learn programming. But if I’ve never been exposed to programming, why should I invest all of the effort to learn? What’s in it for me? When I was confronted with data limitation challenge in spreadsheet (Brown, 2001), and the issue of repeating the same process over and over again, I decided to learn to program. I started learning R— a statistical and graphical software (James, Witten, Hastie, &amp;amp; Tibshirani, 2013).</description>
    </item>
    
    <item>
      <title>Publishing Our Academic  Dissertation to Broad Audiences</title>
      <link>/11/14/2018/publishing-our-academic-dissertation-to-broad-audiences/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/11/14/2018/publishing-our-academic-dissertation-to-broad-audiences/</guid>
      <description>For years I used Word Processors to prepare manuscript for publication and report. And I used Adobe Indesign whenever I was consulted for typsetting and layout of the books. Adobe suite—a combination of design software was a tool that I often used in my machine. These tools includes Adobe Photoshop, Adobe Indesign and Adobe Illustrator. I prepared the text in Microsoft word and imported it into Indesign for typesetting and layout.</description>
    </item>
    
    <item>
      <title>Read netCDF file with in R</title>
      <link>/11/07/2018/read-netcdf-file-with-in-r/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/11/07/2018/read-netcdf-file-with-in-r/</guid>
      <description>In the previously post, I covered how to read and convert netCDF files directly into R and convert to data frames. The approach is simple and straight forward but there flaws in this approach. One main setback of this approach is its inability to read maltiple matrix in an array from a netcdf file. This inability end up obtain a data frame from the of the first matrice of an array dropping out other matrix.</description>
    </item>
    
    <item>
      <title>Read and Convert netcdf files into data frame in R</title>
      <link>/11/03/2018/converting-netcdf-files-into-data-frame/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/11/03/2018/converting-netcdf-files-into-data-frame/</guid>
      <description>Scientist often store most of oceanographic and environmental variables from satellite sensors in netCDF format. The netCDF data file format contain one or more variables, which are usually structured as regular arrays and metadata describing the contents and format of the data. For example, you might have a variable named “Temperature” that is a function of longitude, latitude, and depth. NetCDF files also contain dimensions, which describe the extent of the variables’ arrays.</description>
    </item>
    
    <item>
      <title>Animating Oceanographic data in R with ggplot2 and gganimate</title>
      <link>/10/29/2018/animating-oceanographic-data-in-r-with-ggplot2-and-gganimate/</link>
      <pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/29/2018/animating-oceanographic-data-in-r-with-ggplot2-and-gganimate/</guid>
      <description>setwd(&amp;quot;E:/Data Manipulation/xtractomatic&amp;quot;)IntroductionThe increasing popularity of ggplot2 package (Wickham, 2016) had made many people becomes familiar with art of grammer of graphics of static plots. But, most of environmental data are static but rather changes both with time and space. Therefore, animated plots are effective way to communicate these dind of data.
Pedersen &amp;amp; Robinson (2017) developed gganimate package that extends the grammar of graphic as implemented with ggplot2 with animations.</description>
    </item>
    
    <item>
      <title>Access and Process Quikscat Wind speed and direction with R</title>
      <link>/10/27/2018/access-and-process-quikscat-wind-speed-and-direction-with-r/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/27/2018/access-and-process-quikscat-wind-speed-and-direction-with-r/</guid>
      <description>quikscatIn his An Introduction to the Near–Real–Time QuikSCAT Data, Hoffman (2005) described the primary mission of the SeaWinds instrument on the National Aeronautics and Space Administration (NASA) Quick Scatterometer (QuikSCAT ) satellite was to retrieve the surface vector wind over the global ocean (Lungu 2001).
QuikSCAT has provided an extremely accurate and extraordinarily comprehensive view of the surface wind over the global ocean since July 1999 (Chelton et al.</description>
    </item>
    
    <item>
      <title>Processing Satellite Wind Speed Data with R</title>
      <link>/10/25/2018/processing-satellite-wind-speed-data-with-r/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/25/2018/processing-satellite-wind-speed-data-with-r/</guid>
      <description>The Advanced Scatterometer (ASCAT) winds products are processed by NOAA/NESDIS utilizing measurements from the scatterometer instrument aboard the EUMETSAT Metop satellites. The instrument uses radar to measure backscatter to determine speed and direction of winds over the surface of the oceans. ASCAT observations fields have regular spatial resolutions of 0.25° in longitude and latitude.
The daily wind fields are calculated in near real time with a delay of 48 hours.</description>
    </item>
    
    <item>
      <title>Expore Current Velocity Measured with  ADCP in R</title>
      <link>/10/18/2018/expore-current-velocity-measured-with-adcp-in-r/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/18/2018/expore-current-velocity-measured-with-adcp-in-r/</guid>
      <description>PackagesWe need some packages to process ADCP data. These packages includes
require(oce)require(tidyverse)require(visdat)require(naniar)require(UpSetR)Ingest the ADCPThe LTA dataset was imported into R with read.adp() function from oce package
pemba = read.adp(&amp;quot;./adcp/ADCP_DATA/2007_05/M72-5_OS75011_000000.LTA&amp;quot;)Extract variables containedThe ADCP was collected using the broadband instrument with a frequency of 75KHz making a total of 100 cells spaced at an interval of 16 m making a profile of 1600 m deep.</description>
    </item>
    
    <item>
      <title>CTD Data in R with oce and tidyverse package</title>
      <link>/10/05/2018/ctd-data-in-r-with-oce-and-tidyverse-package/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/05/2018/ctd-data-in-r-with-oce-and-tidyverse-package/</guid>
      <description>Introductionin the previous post, we looked at CTD processing and visualization of profile and section with oce package. We saw the necessary tools needed to import, transform and even plotting oceanographic standard graphics. This post introduce to an ecosystem of packages called tidyverse. The three packages in tidyverse that people use in everyday data analyses include the grammer for graphic ggplot develop by Wickham (2016) for data visualization.</description>
    </item>
    
    <item>
      <title>Seasonal Climatology of temperature and salinity in the WIO region from Argo floats </title>
      <link>/10/03/2018/seasonal-climatology-of-temperature-and-salinity-in-the-wio-region-from-argo-floats/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/03/2018/seasonal-climatology-of-temperature-and-salinity-in-the-wio-region-from-argo-floats/</guid>
      <description>IntroductionFor years oceanographers have measured temperature and salinity from the surface to the ocean bottom (Foster, 1983). However, our ability to obtain reliable temperature and salinity profiles at fairly resolution both in location and time has been improved through the use of profiling floats from the Argo program (Roemmich et al., 2009; Rosell-Fieschi, 2014; Vilibić &amp;amp; Mihanović, 2013). The Argo program started in the early 2000s with the prime objective of monitoring the upper layer of the world oceans (Rosell-Fieschi, 2014).</description>
    </item>
    
    <item>
      <title>Linear Model with R</title>
      <link>/10/02/2018/modelling-with-r/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/02/2018/modelling-with-r/</guid>
      <description>IntroductionIn this post I’am going to illustrate how to model in R. As Wickham &amp;amp; Grolemund1 put it
The prime goal of modeling is to provide simple low-dimension summary of a dataset.
I am not going to bring a novel science in this post but rather to help you learn the most important tools in R2 that will allow you to model your data.</description>
    </item>
    
    <item>
      <title>Drifter-derived seasonal climatology of Sea surface temperature in the Tropical Indian Ocean</title>
      <link>/09/30/2018/sea-surface-temperature-from-drifter/</link>
      <pubDate>Sun, 30 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/30/2018/sea-surface-temperature-from-drifter/</guid>
      <description>The study of sea surface temperature (SST) is one of the cornerstone of oceanography. It has applications not only in physics (Bader &amp;amp; Latif, 2003), chemistry (Corrège, 2006) and the earth’s sciences, but in subjects as diverse as biology and economics. SST plays an important role in our quantitative understanding of coastal habitats and species distribution in our global oceans (Grémillet et al., 2008; Müller-Karger, Walsh, Evans, &amp;amp; Meyers, 1991).</description>
    </item>
    
    <item>
      <title>Surface current in the Tropical Indian Ocean Region from Drifter Observations</title>
      <link>/09/28/2018/surface-current-from-drifters/</link>
      <pubDate>Fri, 28 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/28/2018/surface-current-from-drifters/</guid>
      <description>IntroductionIn the previous post I showed how to track the East African Coastal Current using trajectories od drifters. In this post, we dive deeper, focusing on creating grids and fill them with number of drifter the median surface current and present them in form of maps. The goal of this routine is to illustrate how to process drifter data in R using tidyverse and other packages.
Needed PackagesWe need to load some packages into R that are used to process the data.</description>
    </item>
    
    <item>
      <title>The East African Coastal Current captured with satellite-tracked drifter observations</title>
      <link>/09/26/2018/chase-the-east-african-coastal-current-with-satellite-tracked-drifter-observations/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/26/2018/chase-the-east-african-coastal-current-with-satellite-tracked-drifter-observations/</guid>
      <description>My interest to explore the EACC comes from its role in linking the boundary currents north of Madagascar and at the equator. It is long established that the East African Coastal Current flows northward along the coast of Tanzania throughout the year1. However, until now we have a rough sketch of the East african coastal current and its seanoal variations. In this post, I am going to illustrate to you how to process drifter data that capture nicely the pathways of the EACC.</description>
    </item>
    
    <item>
      <title>Surface Current in Pemba channel: Drifter Perspective</title>
      <link>/09/24/2018/surface-current-in-pemba-channel-drifter-perspective/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/24/2018/surface-current-in-pemba-channel-drifter-perspective/</guid>
      <description>IntroductionSurface Currents are driven by global wind systems that are fueled by energy from the sun1. These currents inturn transfer heat from the tropics to the polar regions, influencing local and global climate2. Ocean currents are an important abiotic factor that significantly influences food webs and reproduction of marine organisms and the marine ecosystems that they inhabit3. Many species with limited mobility depend on this “liquid wind” to bring food and nutrients to them and to distribute larvae and reproductive cells.</description>
    </item>
    
    <item>
      <title>Processing CTD measurements in R with Oce and tidyverse packages</title>
      <link>/09/22/2018/processing-ctd-measurements-in-r-with-oce-and-tidyverse-packages/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/22/2018/processing-ctd-measurements-in-r-with-oce-and-tidyverse-packages/</guid>
      <description>In the previous post, I illustrate how to process ship-based CTD data with oce1 package in R2 enviroment. We saw the power of this package in reading, summarizing and visualizing CTD data. The downside of oce package in my opinion is its strickest nature of relying on R base for data processing and plotting—preventing customization. Therefore, in this post I will illustrate how to tranforming oce dataset format into a tibble—a modern data frame.</description>
    </item>
    
    <item>
      <title>Validating MODIS Sea Surface Temperature with Global Drifter Program Observations</title>
      <link>/09/20/2018/validating-modis-sea-surface-temperature-with-global-drifter-program-observations/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/20/2018/validating-modis-sea-surface-temperature-with-global-drifter-program-observations/</guid>
      <description>IntroductionIn this post, I am going to illustrate routines of how to validate sea surface temperatures from Moderate Resolution Imaging Spectroradiometer (MODIS) with drifters’ sea surface temperature. Drifters measurements serve as in-situ data against MODIS data. The purpose is to assess closeneness (accuracy) of satellite and in-situ SST. I will check the accuracy of acquired (satellite) and measured (drifter) SST, visualize their relationship and test the significance of the relationship.</description>
    </item>
    
    <item>
      <title>Getting and Processing Satellite Data made easier in R</title>
      <link>/09/18/2018/get-satellite-data-with-r/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/18/2018/get-satellite-data-with-r/</guid>
      <description>Introduction: A Brief OverviewThe amount of data being generated by satellites has soared in recent years. The proliferation of remote sensing data can be explained by recent advancements in satellite technologies. However, according to Febvre1, this advancement set another challenge of handling and processing pentabyte of data satellite generates. Thanks to ERDDAP, for being in front-line to overcome this challenge. We can obtain satellite data within the geographical extent of the area we are interested.</description>
    </item>
    
  </channel>
</rss>