<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tanzania on Masumbuko Semba&#39;s Blog</title>
    <link>/tags/tanzania/</link>
    <description>Recent content in Tanzania on Masumbuko Semba&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/tanzania/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python as a tool for oceagraphy and marine sciences</title>
      <link>/07/02/2020/python-as-a-tool-for-oceagraphy-and-marine-sciences/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/07/02/2020/python-as-a-tool-for-oceagraphy-and-marine-sciences/</guid>
      <description>During the last couple of decades, Matlab has been the most commonly-used scripting language in physical oceanography (Bengtsson 2018), and it has a large user base in many other fields. However, Python has been gaining ground, often being adopted by former Matlab users as well as by newcomers. Here is a little background to help you understand this shift, and why we advocate using Python from the start.
Python was designed by a computer scientist as a general–purpose scripting language for easy adoption and widespread use.</description>
    </item>
    
    <item>
      <title>Kernel smoothing of Spatial Data</title>
      <link>/06/30/2020/kernel-smoothin-of-spatial-data/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/30/2020/kernel-smoothin-of-spatial-data/</guid>
      <description>Kernel density estimation is a popular tool for visualizing the distribution of data. In this post, we are going to look on how to create smoothed map of random points. We will use a shapefile dataset that contains potential fishing zones derived from sea surface temperature recorded between January and June 2020 in Pemba channel. You can simply download the file from this link.
Once you have downloaded the file, unzip and browse in the uncompressed file you find the shapefile pfz.</description>
    </item>
    
    <item>
      <title>Processing NECTA Results in R</title>
      <link>/06/14/2020/processing-necta-results-in-r/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/14/2020/processing-necta-results-in-r/</guid>
      <description>The the National Examinations Council of Tanzania publishes Primary and Secondary Education Examination Results. But the National Library Services archieve this results. While a fantastic resource for history primary and secondary school results, these records are painful to analyze using software because of the grades results is organized is untidy and in messy.
You need to work on this column of the result to have a clean and right format dataset for exploration and modelling.</description>
    </item>
    
    <item>
      <title>Linear and Bayesian Regression Models with tidymodels package</title>
      <link>/05/11/2020/regression-with-tidymodels/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/11/2020/regression-with-tidymodels/</guid>
      <description>As a data scientist, you need to distinguish between regression predictive models and classification predictive models. Clear understanding of these models helps to choose the best one for a specific use case. In a nutshell, regression predictive models andclassification predictive models` fall under supervised machine learning. The main difference between them is that the output variable—in regression is numerical (or continuous) while that for classification is categorical (or discrete).</description>
    </item>
    
    <item>
      <title>Heatmaps in R with ggplot2 and metR packages </title>
      <link>/05/10/2020/heatmaps-in-r-with-ggplot2-and-metr-packages/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/10/2020/heatmaps-in-r-with-ggplot2-and-metr-packages/</guid>
      <description>Heatmaps are powerful data visualization tools broadly widely used with meteorologic and oceanographic data. Heatmaps are excellent at tracking signals that move, like ocean current. These diagrams can be used for many more types of atmospheric features. The concept is to represent a matrix of values as colors where usually is organized by a gradient. This post explains how to create a heatmap of ocean current in R using the geom_tile(), geom_contour_filled from ggplot2 (Wickham 2016) and geom_contour_fill from metR package (Campitelli 2019).</description>
    </item>
    
    <item>
      <title>A Unified Machine Learning in R with tidymodels</title>
      <link>/05/09/2020/a-unified-machine-learning-in-r-with-tidymodels/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/09/2020/a-unified-machine-learning-in-r-with-tidymodels/</guid>
      <description>tidymodelstidymodels is a suite of packages that make machine learning with R a breeze. R has many packages for machine learning, each with their own syntax and function arguments. tidymodels aims to provide an unified interface, which allows data scientists to focus on the problem they’re trying to solve, instead of wasting time with learning package syntax.
The tidymodels has a modular approach meaning that specific, smaller packages designed to work hand in hand.</description>
    </item>
    
    <item>
      <title>Convert incorrect filled missing values to NA in R data frame</title>
      <link>/05/06/2020/conver-improper-filled-missing-values-to-na-in-r/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/05/06/2020/conver-improper-filled-missing-values-to-na-in-r/</guid>
      <description>One of the most important components of a data management strategy is the proper handling of missing values. Often you will find datasets that have used either zero or NA to represent missing values in cell of a data frame or table. The question that may sober our mind is that, which of the two way of storing missing value in the data is right? You will notice that everyone who deals with data has to deal with this important distinction.</description>
    </item>
    
    <item>
      <title>Lake Victoria Bathymetry</title>
      <link>/04/24/2020/lake-victoria-bathymetry/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/04/24/2020/lake-victoria-bathymetry/</guid>
      <description>I was looking for bathymetry dataset for Lake Victoria online and I came across this link. It stores several products of the bathymetry data of the Lake Victoria. Among them products is the gridded TIFF file. This dataset was created by a team from Harvard University in 2017 (Hamilton et al. 2016). They used over 4.2 million points collected over 100-years of surveys.</description>
    </item>
    
    <item>
      <title>plotting the Spatial distribution of Chlorophyll in Mafia Channel from MODIS</title>
      <link>/12/01/2019/plotting-the-spatial-distribution-of-chlorophyll-from-modis/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/12/01/2019/plotting-the-spatial-distribution-of-chlorophyll-from-modis/</guid>
      <description>Making graphics and maps is one of the important skills for oceanographers and marine scientists. Maps are often used by scientists to locate areas of interest—where the study being presented was conducted. Thus ability to make maps that convey the message in a simple manner form an important first impression for readers. Despite this, software tools for producing high-quality maps are non-trivial to use.
In this post I illustrate how some key lines of code for access, download and map the spatial distribution of chlorophyll-a concentration within the Rufiji-Mafia Channel using a combination of packages in the R environment.</description>
    </item>
    
    <item>
      <title>A glimpse of FAO&#39; fisheries statistics in R</title>
      <link>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</guid>
      <description>IntroductionThe OpenFisheries.org project created an open web platform aimed to advance the practice of data science in fisheries. The project has managed to consolidate global fisheries dataset that can be accessed and retrieved using modern analytics. The OpenFisheries.org flagship project is the Global Fisheries REST API forms the backbone of fisheries data science, enabling reproducible analytics in R (R Core Team, 2019), Python or any other language.</description>
    </item>
    
    <item>
      <title>Interactive map with leaflet</title>
      <link>/03/17/2019/interactive-map-with-leaflet/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/03/17/2019/interactive-map-with-leaflet/</guid>
      <description>This post aim to train you how to make an interactive in R. We are going to focus on some poular packages for these task, many are part onf an tidyverse ecosystem (Wickham 2017) with addition of leaflet(Cheng, Karambelkar, and Xie 2018) package. To work with these post you need to have version 3.4 and above of R(R Core Team 2018) installed in your machine.</description>
    </item>
    
    <item>
      <title>Exploring Time Series Data in R</title>
      <link>/02/22/2019/exploring-time-series-data-in-r/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/22/2019/exploring-time-series-data-in-r/</guid>
      <description>IntroductionShumway and Stoffer (2017) in the book with a title Time series analysis and its applications: with R examples clearly stated that when dealing with any time series analysis the first step you ought to do befure further investigation is careful examination of the recorded data. This means before looking more closely at the particular statistical methods, it is appropriate to plot the recorded data against time. This scrutiny often suggests the method of analysis as well as statistics that will be of use in summarizing the information in the data.</description>
    </item>
    
    <item>
      <title>Time series analysis in R</title>
      <link>/02/20/2019/time-series-analysis-in-r/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/20/2019/time-series-analysis-in-r/</guid>
      <description>Any quantitative value measured over regular time intervals makes a Time Series. Time-series analysis aims to investigate the temporal behavior of a variable \(X_{t}\). Examples include the investigation of long-term records of sea surface temperature, sea-level fluctuations, millennium-scale variations in the atmosphere-ocean system, the eff ect of the El-Niño/Southern Oscillation on tropical rainfall and sedimentation (Trauth 2015). R has extensive facilities for analyzing time series data. These packages provides various tools with which to detect these temporal patterns.</description>
    </item>
    
    <item>
      <title>Mapping the bathymetry of Coastal Tanzania from ETOPO1 with oce package in R</title>
      <link>/02/14/2019/mapping-the-bathmetry-of-coastal-tanzania-from-etopo1-with-oce-package-in-r/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/14/2019/mapping-the-bathmetry-of-coastal-tanzania-from-etopo1-with-oce-package-in-r/</guid>
      <description>In the previous post, we explore the power of oce package in mapping oceanographic data. In this post we will continue that theme and dive to process topographic data and map the bathymetry. We will grab ETOPO1 dataset— a 1 arc-minute global relief model that integrates land topography and ocean bathymetry. We will process the data and then use different ways to visualize the bathymetric information. There is no much statistics or modelling in this post, but the post focus on letting you know how to process the ascii (.</description>
    </item>
    
    <item>
      <title>Comparing classical methods for estimating the mixed layer depth along the transect off Kimbiji, Tanzania</title>
      <link>/02/09/2019/comparing-classical-methods-for-estimating-the-mixed-layer-depth-along-the-transect-off-kimbiji-tanzania/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/02/09/2019/comparing-classical-methods-for-estimating-the-mixed-layer-depth-along-the-transect-off-kimbiji-tanzania/</guid>
      <description>IntroductionUpper Ocean is characterized for a quasi-homogeneous layer where temperature, salinity and density almost constant with increasing depth (Costoya et al. 2014). This homogeneity layer is caused by turbulent vertical mixing that is driven by heat loss from the ocean to the atmosphere, as well as by wind stress (Stranne et al. 2018). The deepest layer affected by this turbulent mixing is called mixed layer depth (MLD), which marks the width of the upper ocean that interacts with the atmosphere (Kelley 2018).</description>
    </item>
    
    <item>
      <title>Access and Process Quikscat Wind speed and direction with R</title>
      <link>/10/27/2018/access-and-process-quikscat-wind-speed-and-direction-with-r/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/27/2018/access-and-process-quikscat-wind-speed-and-direction-with-r/</guid>
      <description>quikscatIn his An Introduction to the Near–Real–Time QuikSCAT Data, Hoffman (2005) described the primary mission of the SeaWinds instrument on the National Aeronautics and Space Administration (NASA) Quick Scatterometer (QuikSCAT ) satellite was to retrieve the surface vector wind over the global ocean (Lungu 2001).
QuikSCAT has provided an extremely accurate and extraordinarily comprehensive view of the surface wind over the global ocean since July 1999 (Chelton et al.</description>
    </item>
    
    <item>
      <title>Processing Satellite Wind Speed Data with R</title>
      <link>/10/25/2018/processing-satellite-wind-speed-data-with-r/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/25/2018/processing-satellite-wind-speed-data-with-r/</guid>
      <description>The Advanced Scatterometer (ASCAT) winds products are processed by NOAA/NESDIS utilizing measurements from the scatterometer instrument aboard the EUMETSAT Metop satellites. The instrument uses radar to measure backscatter to determine speed and direction of winds over the surface of the oceans. ASCAT observations fields have regular spatial resolutions of 0.25° in longitude and latitude.
The daily wind fields are calculated in near real time with a delay of 48 hours.</description>
    </item>
    
    <item>
      <title>Processing  CTD data with OCE package in R</title>
      <link>/10/04/2018/processing-ctd-data-with-oce-package-in-r/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/10/04/2018/processing-ctd-data-with-oce-package-in-r/</guid>
      <description>Oceanographers love MATLAB\(^\circledR\) for processing oceanographic data. I have no explanation as to why they love Matlab. I suppose it’s been the de facto standard within the field for a long time, and legacy is a big deal. I have used Matlab for data processing and plotting for several years. With MatLab I implemented a vast amount of tools and rather completed numerical models. Being a self sponsored graduate student at an institution that doesn’t have a subscription, I found sticking to Matlab not only is expensive, but also unsustainable.</description>
    </item>
    
    <item>
      <title>Surface current in the Tropical Indian Ocean Region from Drifter Observations</title>
      <link>/09/28/2018/surface-current-from-drifters/</link>
      <pubDate>Fri, 28 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/28/2018/surface-current-from-drifters/</guid>
      <description>IntroductionIn the previous post I showed how to track the East African Coastal Current using trajectories od drifters. In this post, we dive deeper, focusing on creating grids and fill them with number of drifter the median surface current and present them in form of maps. The goal of this routine is to illustrate how to process drifter data in R using tidyverse and other packages.
Needed PackagesWe need to load some packages into R that are used to process the data.</description>
    </item>
    
    <item>
      <title>Processing CTD measurements in R with Oce and tidyverse packages</title>
      <link>/09/22/2018/processing-ctd-measurements-in-r-with-oce-and-tidyverse-packages/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/09/22/2018/processing-ctd-measurements-in-r-with-oce-and-tidyverse-packages/</guid>
      <description>In the previous post, I illustrate how to process ship-based CTD data with oce1 package in R2 enviroment. We saw the power of this package in reading, summarizing and visualizing CTD data. The downside of oce package in my opinion is its strickest nature of relying on R base for data processing and plotting—preventing customization. Therefore, in this post I will illustrate how to tranforming oce dataset format into a tibble—a modern data frame.</description>
    </item>
    
  </channel>
</rss>