<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Semba on Masumbuko Semba&#39;s Blog</title>
    <link>/tags/semba/</link>
    <description>Recent content in Semba on Masumbuko Semba&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/semba/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Download satellite data in tidy form with rerddapp in R</title>
      <link>/09/30/2020/download-satellite-data-in-tidy-form-with-rerddapp-in-r/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/09/30/2020/download-satellite-data-in-tidy-form-with-rerddapp-in-r/</guid>
      <description>In the post titled Access, Download, Process and VIsualize sea surface height and geostrophic current from AVISO in R posted in my blog on Monday, Apr 15, 2019, I explained how we can download the satellite data like sea surface height from AVISO in R. I illustrate in detail getting the data using xtractomatic package (Mendelssohn 2018). Though xtractomatic package provide functions that allows us to get access to the ERDDAP server and get the data, but one big challenge is that the data comes is array and need an expensive computation process, especially if you deal with gridded data for a long term time series.</description>
    </item>
    
    <item>
      <title>Compute the annual trend in temperature in R with EnvStats</title>
      <link>/09/23/2020/compute-the-annual-trend-in-temperature-in-r-with-envstats/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/09/23/2020/compute-the-annual-trend-in-temperature-in-r-with-envstats/</guid>
      <description>IntroductionOften in environmental studies we are interested in assessing the presence or absence of a long term trend. A widely applied is a parametric test for trend, which involves fitting a linear model that includes some measure of time as one of the predictor variables, and possibly allowing for serially correlated errors in the model. Instead of fitting the data to time series parametric test, Stephen Millard bundles several functions in EnvStats package that are non–parametric and agnostic in dealing with trend (Millard 2013).</description>
    </item>
    
    <item>
      <title>Integrate R and Python in Rstudio to Power Your Analytical Capability</title>
      <link>/07/10/2020/integrate-r-and-python-in-rstudio-to-power-your-analytical-capability/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/07/10/2020/integrate-r-and-python-in-rstudio-to-power-your-analytical-capability/</guid>
      <description>If you work with data science, R and Python must be the two programming languages that you use the most. Both R and Python are quite robust languages and either one of them is actually sufficient to carry out the data analysis task. However, instead of considering them as tools that supplement each other, more often you will find people dealing with data claim one language to be better than the other.</description>
    </item>
    
    <item>
      <title>Python as a tool for oceagraphy and marine sciences</title>
      <link>/07/02/2020/python-as-a-tool-for-oceagraphy-and-marine-sciences/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/07/02/2020/python-as-a-tool-for-oceagraphy-and-marine-sciences/</guid>
      <description>During the last couple of decades, Matlab has been the most commonly-used scripting language in physical oceanography (Bengtsson 2018), and it has a large user base in many other fields. However, Python has been gaining ground, often being adopted by former Matlab users as well as by newcomers. Here is a little background to help you understand this shift, and why we advocate using Python from the start.
Python was designed by a computer scientist as a general–purpose scripting language for easy adoption and widespread use.</description>
    </item>
    
    <item>
      <title>Processing NECTA Results in R</title>
      <link>/06/14/2020/processing-necta-results-in-r/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/14/2020/processing-necta-results-in-r/</guid>
      <description>The the National Examinations Council of Tanzania publishes Primary and Secondary Education Examination Results. But the National Library Services archieve this results. While a fantastic resource for history primary and secondary school results, these records are painful to analyze using software because of the grades results is organized is untidy and in messy.
You need to work on this column of the result to have a clean and right format dataset for exploration and modelling.</description>
    </item>
    
    <item>
      <title>Interactive Plots and  Maps in R</title>
      <link>/06/13/2020/plots-in-interactive-maps-with-r/</link>
      <pubDate>Sat, 13 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/06/13/2020/plots-in-interactive-maps-with-r/</guid>
      <description>IntroductionOften times when w are working with data, there always a geospatial component to the data—the locations. Most of us have used static maps to reveal information that other plots can not. And interactive maps can enliven geographic information to new insights. The most important type of interactivity, is the display of geographic data on interactive or ‘slippy’ web maps. Interactivity can take many forms, the most common and useful of which is the ability to pan around and zoom into any part of a geographic dataset overlaid on a ‘web map’ to show context.</description>
    </item>
    
    <item>
      <title>Access meteorogical observations using worldmet package</title>
      <link>/11/29/2019/access-meteorogical-observations-using-worldmet-package/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/11/29/2019/access-meteorogical-observations-using-worldmet-package/</guid>
      <description>David Carslaw (2019) developed R package worldmet, which provides an easy way to access world meteorological data from from the Integrated Surface Database of National Oceanic and Atmospheric Administration (NOAA). The Integrated Surface Database (ISD) consists of global hourly and synoptic observations compiled from numerous sources into a single common ASCII format and common data model.</description>
    </item>
    
    <item>
      <title>Wordclouds plotting with ggwordcloud package in R</title>
      <link>/11/05/2019/wordclouds-plotting-with-ggwordcloud-package-in-r/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/11/05/2019/wordclouds-plotting-with-ggwordcloud-package-in-r/</guid>
      <description>In the previous post, we saw how to make wordcloud graphic using the wordcloud package. In this post we extend the ability of R to make wordcloud graphic, but rather than using the base R function for plotting,I will show how to use ggplot2 framework.
Le Pennec and Slowikowski (2019) developed a gwordcloud package, which extend the capability of ggplot2 package (Wickham 2016) of making cloud text. With the geom_text_wordcloud() function, gwordcloud made making wordcloud plot easy with ggplot2 package.</description>
    </item>
    
    <item>
      <title>A glimpse of FAO&#39; fisheries statistics in R</title>
      <link>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/10/16/2019/a-glimpse-of-fao-fisheries-statistics-in-r/</guid>
      <description>IntroductionThe OpenFisheries.org project created an open web platform aimed to advance the practice of data science in fisheries. The project has managed to consolidate global fisheries dataset that can be accessed and retrieved using modern analytics. The OpenFisheries.org flagship project is the Global Fisheries REST API forms the backbone of fisheries data science, enabling reproducible analytics in R (R Core Team, 2019), Python or any other language.</description>
    </item>
    
    <item>
      <title>Forecasting time series data with R</title>
      <link>/08/09/2019/forecasting-time-series-data-with-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/08/09/2019/forecasting-time-series-data-with-r/</guid>
      <description>introductionIn this post I illustrate how to predict the future using the historical data. Time series analysis comprises methods for predicting the future based on the historical in order to extract meaningful statistics and other characteristics of the data. In other words, time series forecasting is the use of a model to predict future values based on previously observed values.</description>
    </item>
    
    <item>
      <title>Pie chart and Donut plot with ggplot2</title>
      <link>/07/12/2019/pie-chart-and-donut-plot-with-ggplot2/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/07/12/2019/pie-chart-and-donut-plot-with-ggplot2/</guid>
      <description>Introductionggplot2 packaged for R developed by Hadley Wickham (2016) provides powerful functions for plotting high quality graphs in R.This package has many functions for creating plots among them are pies and donut charts. Pie charts are widely used for showing proportions of mutually–exclusive categories. A pie chart is a circular graphic divided into slices to illustrate numerical proportion of the categorial variable. In a pie chart, the length of each slice is equivalent to the counts or proportion of that slice.</description>
    </item>
    
  </channel>
</rss>